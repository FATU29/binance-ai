# üîí Security Fix: Model Version Control

## ‚ö†Ô∏è L·ªó h·ªïng b·∫£o m·∫≠t ƒë√£ s·ª≠a (2024-12-25)

### V·∫•n ƒë·ªÅ:
Tr∆∞·ªõc ƒë√¢y, AI API cho ph√©p **client (FE/services) truy·ªÅn `model_version` parameter**, g√¢y ra:

1. **üí∞ T·ªën chi ph√≠**: User c√≥ th·ªÉ ch·ªçn `gpt-4` (ƒë·∫Øt) thay v√¨ `gpt-4o-mini` (r·∫ª)
2. **üîì L·ªô th√¥ng tin**: Expose model names v√† c·∫•u h√¨nh AI ra ngo√†i
3. **‚ö†Ô∏è M·∫•t ki·ªÉm so√°t**: Kh√¥ng th·ªÉ ƒë·∫£m b·∫£o consistency v·ªÅ AI behavior
4. **üêõ Risk**: C√≥ th·ªÉ g·ª≠i invalid model names g√¢y crash

### V√≠ d·ª• l·ªó h·ªïng:
```typescript
// ‚ùå TR∆Ø·ªöC ƒê√ÇY (L·ªñ H·ªîNG)
await analyzeSentiment("Bitcoin surges", "gpt-4");  // Client t·ª± ch·ªçn model ƒë·∫Øt!
```

---

## ‚úÖ Gi·∫£i ph√°p ƒë√£ implement

### 1. Remove `model_version` t·ª´ API endpoints

**File: `app/api/v1/endpoints/ai_analytics.py`**

#### Endpoint 1: `/analyze/news/{article_id}`
```python
# ‚ùå BEFORE
async def analyze_news_article(
    article_id: int,
    db: DBSession,
    model_version: str | None = None,  # ‚ùå Client controlled
) -> SentimentAnalysisResponse:

# ‚úÖ AFTER
async def analyze_news_article(
    article_id: int,
    db: DBSession,
) -> SentimentAnalysisResponse:
    # Model controlled by server config only
```

#### Endpoint 2: `/analyze/batch`
```python
# ‚ùå BEFORE
async def analyze_batch_texts(
    texts: list[str],
    model_version: str | None = None,  # ‚ùå Client controlled
)

# ‚úÖ AFTER
async def analyze_batch_texts(
    texts: list[str],
) # Model controlled by server config only
```

#### Endpoint 3: `/analyze/quick`
```python
# ‚ùå BEFORE
async def quick_sentiment_analysis(
    text: str,
    use_openai: bool = True,
    model_version: str | None = None,  # ‚ùå Client controlled
)

# ‚úÖ AFTER
async def quick_sentiment_analysis(
    text: str,
    use_openai: bool = True,
) # Model controlled by server config only
```

---

### 2. Remove `model_version` t·ª´ Request Schema

**File: `app/schemas/sentiment.py`**

```python
# ‚ùå BEFORE
class SentimentAnalysisRequest(BaseSchema):
    text: str = Field(..., min_length=1, max_length=10000)
    model_version: str | None = Field("v1.0.0", max_length=50)  # ‚ùå

# ‚úÖ AFTER
class SentimentAnalysisRequest(BaseSchema):
    """Schema for sentiment analysis request (text input).
    
    Note: Model version is controlled server-side via config, not client input.
    This prevents cost manipulation and ensures consistent AI behavior.
    """
    text: str = Field(..., min_length=1, max_length=10000)
    # No model_version field - controlled by server
```

---

### 3. Server-side Configuration Only

**File: `app/core/config.py`**

```python
class Settings(BaseSettings):
    # ... existing settings ...
    
    # ‚úÖ AI Configuration (server-side only, never expose to clients)
    OPENAI_MODEL: str = Field(
        default="gpt-4o-mini",
        description="OpenAI model for sentiment analysis (controlled server-side for cost/security)"
    )
    OPENAI_MAX_TOKENS: int = Field(
        default=200,
        description="Maximum tokens for OpenAI responses"
    )
    OPENAI_TEMPERATURE: float = Field(
        default=0.3,
        ge=0.0,
        le=2.0,
        description="OpenAI temperature for response consistency"
    )
```

**Environment Variables (`.env`)**:
```bash
# AI Configuration - Server Side Only
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini     # Cost-effective default
OPENAI_MAX_TOKENS=200
OPENAI_TEMPERATURE=0.3
```

---

### 4. Update Service Logic

**File: `app/services/sentiment_service.py`**

```python
class SentimentService:
    def __init__(self) -> None:
        """Initialize with server-controlled config only."""
        # ‚úÖ Load from settings (environment variables)
        self.model_version = settings.OPENAI_MODEL
        self.max_tokens = settings.OPENAI_MAX_TOKENS
        self.temperature = settings.OPENAI_TEMPERATURE
        self.client: AsyncOpenAI | None = None
        
        if settings.OPENAI_API_KEY:
            self.client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info(
                "OpenAI client initialized",
                model=self.model_version,  # ‚úÖ Server controlled
                max_tokens=self.max_tokens,
                temperature=self.temperature,
            )

    async def _analyze_with_openai(self, request: SentimentAnalysisRequest):
        # ‚úÖ Use server config only
        response = await self.client.chat.completions.create(
            model=self.model_version,      # ‚úÖ From settings
            temperature=self.temperature,  # ‚úÖ From settings
            max_tokens=self.max_tokens,    # ‚úÖ From settings
            messages=[...],
        )
```

---

## üìã Migration Guide cho Frontend

### API Calls - Before vs After

```typescript
// ‚ùå BEFORE (with model_version parameter)
const response = await axios.post('/ai/analyze/quick', null, {
  params: { 
    text: "Bitcoin surges", 
    use_openai: true,
    model_version: "gpt-4"  // ‚ùå NOT ALLOWED ANYMORE
  }
});

// ‚úÖ AFTER (no model parameter)
const response = await axios.post('/ai/analyze/quick', null, {
  params: { 
    text: "Bitcoin surges", 
    use_openai: true
    // ‚úÖ Model controlled by server
  }
});
```

### TypeScript API Client Update

```typescript
// ‚úÖ Updated function signature
export async function analyzeSentiment(text: string): Promise<SentimentResult> {
  const { data } = await aiApi.post('/ai/analyze/quick', null, {
    params: { 
      text, 
      use_openai: true 
      // NO model_version parameter
    }
  });
  return data;
}

export async function analyzeBatch(texts: string[]): Promise<SentimentResult[]> {
  const { data } = await aiApi.post('/ai/analyze/batch', { texts });
  // NO model_version in request body
  return data;
}
```

---

## üéØ Benefits

### 1. **Cost Control** üí∞
- Admin ki·ªÉm so√°t 100% model n√†o ƒë∆∞·ª£c d√πng
- C√≥ th·ªÉ switch model m√† kh√¥ng c·∫ßn deploy FE
- NgƒÉn abuse: user kh√¥ng th·ªÉ ch·ªçn model ƒë·∫Øt

### 2. **Security** üîí
- Kh√¥ng expose model names/versions ra client
- Kh√¥ng expose API configuration
- Gi·∫£m attack surface

### 3. **Consistency** üéØ
- T·∫•t c·∫£ requests d√πng c√πng model ‚Üí consistent results
- D·ªÖ A/B testing (change `.env` only)
- Centralized configuration

### 4. **Flexibility** üîÑ
- Admin c√≥ th·ªÉ switch model b·∫•t k·ª≥ l√∫c n√†o
- Update `OPENAI_MODEL=gpt-4o` trong `.env` ‚Üí t·∫•t c·∫£ requests d√πng model m·ªõi
- Kh√¥ng c·∫ßn redeploy frontend

---

## üß™ Testing

### Test 1: Verify model kh√¥ng th·ªÉ override
```bash
# Try to pass model_version (should be ignored)
curl -X POST "http://localhost:8000/api/v1/ai/analyze/quick?text=Bitcoin%20surges&use_openai=true" \
  -H "Content-Type: application/json"

# Response will use server-configured model (gpt-4o-mini by default)
```

### Test 2: Verify settings work
```bash
# In .env file:
# OPENAI_MODEL=gpt-4o-mini

# Start server
cd ai
uv run fastapi dev main.py

# Check logs - should show:
# OpenAI client initialized model=gpt-4o-mini max_tokens=200 temperature=0.3
```

### Test 3: Verify FE integration
```typescript
// Frontend code
const result = await analyzeSentiment("Bitcoin crashes");
console.log(result.model_version); // Should be "gpt-4o-mini" (from server)
```

---

## üìù Admin Guide: Changing AI Model

### Option 1: Environment Variable (Recommended)
```bash
# Edit ai/.env
OPENAI_MODEL=gpt-4o        # Upgrade to more powerful model
OPENAI_MAX_TOKENS=500      # Allow longer responses
OPENAI_TEMPERATURE=0.5     # More creative responses

# Restart service
docker-compose restart ai-service
```

### Option 2: Docker Compose
```yaml
# docker-compose.yml
services:
  ai-service:
    environment:
      - OPENAI_MODEL=gpt-4o-mini  # Control here
      - OPENAI_MAX_TOKENS=200
      - OPENAI_TEMPERATURE=0.3
```

### Option 3: Kubernetes ConfigMap
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-service-config
data:
  OPENAI_MODEL: "gpt-4o-mini"
  OPENAI_MAX_TOKENS: "200"
  OPENAI_TEMPERATURE: "0.3"
```

---

## üîç Code Changes Summary

### Files Modified:
1. ‚úÖ `app/api/v1/endpoints/ai_analytics.py` - Removed `model_version` params from 3 endpoints
2. ‚úÖ `app/schemas/sentiment.py` - Removed `model_version` field from request schema
3. ‚úÖ `app/core/config.py` - Added `OPENAI_MODEL`, `OPENAI_MAX_TOKENS`, `OPENAI_TEMPERATURE` settings
4. ‚úÖ `app/services/sentiment_service.py` - Load config from settings instead of params

### Files to Update (Frontend):
- ‚ö†Ô∏è `fe/lib/services/ai-api.ts` - Remove model_version parameters from function calls
- ‚ö†Ô∏è Any FE components passing model_version

### Breaking Changes:
- ‚ùå `model_version` parameter no longer accepted in API calls
- ‚úÖ Existing calls without `model_version` continue to work
- ‚úÖ Calls with `model_version` will **ignore** the parameter (not error)

---

## üöÄ Deployment Checklist

- [x] Update backend code (3 endpoints + schema + service)
- [x] Add settings configuration
- [ ] Update `.env` with AI config
- [ ] Test endpoints without model_version
- [ ] Update FE API client code
- [ ] Test FE integration
- [ ] Update API documentation
- [ ] Deploy to staging
- [ ] Deploy to production

---

## üìö Related Documentation

- `FE_IMPLEMENTATION_PRIORITY.md` - Frontend integration guide (needs update)
- `COPY_PASTE_AI_INTEGRATION.md` - Quick start guide (needs update)
- `OPENAI_GUIDE.md` - OpenAI implementation details

---

**Date**: December 25, 2024  
**Priority**: HIGH - Security & Cost Control  
**Status**: ‚úÖ Fixed in code, pending deployment
